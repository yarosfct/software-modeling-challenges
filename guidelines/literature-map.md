# Thesis Literature MAP — Software Modelling Learning and Teaching

## 1. Thematic Groups

### 1.1 Core methodological and analytical foundations

These papers provide me with the method toolbox and analytical lenses:

- **Understanding the challenges and requirements for facilitating iStar learning: An empirical study with iStar learners**
- **Grounded Theory in Software Engineering Research: A Critical Review and Guidelines**
- **Socio-Technical Grounded Theory for Software Engineering**
- **A Revision of Bloom's Taxonomy: An Overview**
- **Teaching Survey Research in Software Engineering**
- **Challenges in Survey Research**

**They might be used mainly in:**
> *Methodology, Research Design, Data Collection & Analysis, Instrument Design; and to give structure to Research Questions (Bloom).*

---

### 1.2 Conceptual/modelling education & Bloom

These are about what and how conceptual / domain / data / process modelling are teached, often using Bloom.

- **Conceptual Modeling Education** *(Maslov, Poelmans, Rosenthal)* – bibliometric review
- **Conceptual Modelling in Education: a Position Paper** *(Buchmann et al.)*
- **A Framework for Teaching Conceptual Modeling and Metamodeling Based on Bloom's Revised Taxonomy** *(Bork)*
- **Domain Modelling in Bloom: Deciphering How We Teach It** *(Bogdanova & Snoeck)*
- **CaMeLOT: An educational framework for conceptual data modelling** *(Bogdanova & Snoeck)*

**They might be used mainly in:**
> *Background: "Software / Conceptual Modelling Education", Related Work on modelling pedagogy, and later in Discussion/Implications (when i propose requirements and learning outcomes)*

---

### 1.3 Human factors, motivation, and SE/modelling education more broadly

These give the human/educational context beyond a single notation:

- **Human factors in model-driven engineering: future research goals and initiatives for MDE**
- **Domain Diversity, Motivation, and Inclusion in Software Modelling Education** *(coordinators draft)*
- **Model Driven Software Engineering in Education: A Multi-Case Study on Perception of Tools and UML** *(Liebel et al.)*
- **Dimensions of Experientialism for Software Engineering Education** *(Holmes et al.)*
- **A Research Agenda for Identifying and Developing Required Competencies in Software Engineering** *(Sedelmaier & Landes)*

**They might be used mainly in:**
> *Background: SE Education & Human Factors, Motivation/Problem Statement, and Implications for curriculum & practice.*

---

### 1.4 Exemplars of grounded theory & quantitative SE research

These show how GT is actually used and give me rhetorical models for the Methods section:

- **Using grounded theory to study the experience of software development** *(Adolph et al.)*
- *(Plus GT method papers I already have: Stol et al., Hoda STGT.)*

**Might be used on:**
> *Methodology ("we follow GT/STGT-style...") and as examples in Threats to Validity / Rigor discussions.*

---

## 2. Which papers help which sections of my thesis?

**Possible preliminary thesis structure:**

- **Introduction** (Chapter/Section 1)
  - *Still to be defined*
- **Background** (Chapter/Section 2)
  - 2.1 Software modelling & conceptual modelling
  - 2.2 Modelling education (conceptual, process, goal, UML, MDE)
  - 2.3 Grounded Theory
  - 2.4 Bloom's Taxonomy and learning outcomes
  - 2.5 Human factors in modelling and SE education
- **Related work** (Chapter/Section 3)
  - 3.1 Empirical studies on learning/teaching specific modelling frameworks (iStar, UML, data models)
  - 3.2 Broader SE education work on experience, competencies, experimental learning
  - 3.3 Existing theories/frameworks (CaMeLOT, Domain Modelling in Bloom, etc.)
- **Methodology** (Chapter/Section 4)
  - 4.1 Bloom-based RQs
  - 4.2 Grounded Theory & STGT
  - 4.3 Survey design
  - 4.4 Data collection & analysis

### 2.1 Background – which papers help which subsections?

#### 2.1.1 Software modelling & conceptual modelling

- **Conceptual Modelling in Education: a Position Paper**  
  → *Frames conceptual modelling as its own discipline and explains why modelling matters + common misconceptions.*
- **Conceptual Modeling Education** *(bibliometric review)*  
  → *Big-picture view of research on conceptual / software modelling education (topics, trends, gaps).*
- **Understanding the challenges and requirements for facilitating iStar learning**  
  → *Concrete example of learning/practising a specific modelling framework (iStar) and its challenges.*

#### 2.1.2 Modelling education (conceptual, process, goal, UML, MDE)

- **Conceptual Modeling Education**  
  → *Overall landscape of conceptual modelling education.*
- **Understanding the challenges… iStar learners**  
  → *Goal-oriented / iStar modelling education.*
- **Model Driven Software Engineering in Education: A Multi-Case Study on Perception of Tools and UML**  
  → *Perceptions of UML and MDE tools in education.*
- **Dimensions of Experientialism for Software Engineering Education**  
  → *Context of SE courses and experiential setups where modelling is (or could be) embedded.*
- **A Research Agenda for Identifying and Developing Required Competencies in SE**  
  → *Connects modelling education to broader SE competencies.*

#### 2.1.3 Grounded Theory

- **Grounded Theory in Software Engineering Research: A Critical Review and Guidelines**  
  → *What GT is, variants, core practices, and how it's (mis)used in SE.*
- **Socio-Technical Grounded Theory for Software Engineering**  
  → *Chosen GT method/flavor; explains STGT and why it fits socio-technical phenomena.*
- **Using grounded theory to study the experience of software development**  
  → *Exemplar GT study i can reference as a model for reporting and rigour.*

#### 2.1.4 Bloom's Taxonomy and learning outcomes

- **A Revision of Bloom's Taxonomy: An Overview**  
  → *Base definition of the revised taxonomy (knowledge × cognitive process).*
- **A Framework for Teaching Conceptual Modeling and Metamodeling Based on Bloom's Revised Taxonomy**  
  → *Example of applying Bloom to teaching modelling.*
- **Domain Modelling in Bloom: Deciphering How We Teach It**  
  → *Empirical analysis of domain modelling tasks using Bloom.*
- **CaMeLOT: An educational framework for conceptual data modelling**  
  → *Learning outcomes and teaching framework informed by Bloom.*
- *(Bonus, lighter)* **Teaching Survey Research in SE**  
  → *Shows Bloom levels associated with survey LOs; nice secondary example of Bloom used explicitly in SE education.*

#### 2.1.5 Human factors in modelling and SE education

- **Human factors in model-driven engineering: future research goals and initiatives for MDE**  
  → *Human factors lens on modelling; Section 7 for teaching human-aware MDE.*
- **Domain Diversity, Motivation, and Inclusion in Software Modelling Education**  
  → *Motivation, domain choice, inclusiveness, feedback in modelling courses.*
- **Model Driven Software Engineering in Education: Perception of Tools and UML**  
  → *Human/tool side of MDE in education (complexity, usefulness, frustration).*
- **Dimensions of Experientialism for Software Engineering Education**  
  → *Human experience in SE courses (real projects, mentors, etc.).*
- **A Research Agenda for Identifying and Developing Required Competencies in SE**  
  → *Human-centric view of SE competencies that can tie back to modelling-related skills.*

### 2.2 Related work – which papers help which subsections?

#### 2.2.1 Empirical studies on learning/teaching specific modelling frameworks (iStar, UML, data models)

- **Understanding the challenges and requirements for facilitating iStar learning**  
  → *Direct empirical template: interviews + analysis of **learning challenges** and **requirements** for a specific framework (iStar). I will use it as the closest "baseline" to my study, and as the main example of an in-depth study of learning a single modelling notation.*

- **Model Driven Software Engineering in Education: A Multi-Case Study on Perception of Tools and UML**  
  → *Empirical evidence on how students perceive **UML and MDE tools** (complexity, usefulness, frustration). Fits here as my main empirical reference for UML/MDE education.*

- **Domain Diversity, Motivation, and Inclusion in Software Modelling Education**  
  → *Empirical dual-survey (students + educators) on **domains, assignments, inclusiveness, motivation, feedback** in modelling courses. This shows concrete data on motivation and DEI aspects for modelling assignments.*

- **Human factors in model-driven engineering: future research goals and initiatives for MDE** *(selected parts)*  
  → *Not a single-course empirical study, but it summarises experiences and observations from many researchers; parts of it (especially Sect. 7) can be cited alongside the above as **empirical/experiential evidence** about learning/teaching modelling and feedback/confidence issues.*

#### 2.2.2 Broader SE education work on experience, competencies, experiential learning

- **Dimensions of Experientialism for Software Engineering Education**  
  → *Empirical work on **experiential SE courses** (capstones, real projects) and their benefits/challenges. Can be used to situate how modelling might appear in those contexts and why "authentic tasks" matter.*

- **A Research Agenda for Identifying and Developing Required Competencies in Software Engineering**  
  → *Positions SE education in terms of **competencies** rather than just content; useful to connect modelling-related difficulties to broader SE competencies (e.g., abstraction, communication, requirements).*

- **Conceptual Modeling Education** *(bibliometric review)*  
  → *While it's also background, here i can emphasise its role as **meta-related work**: it maps existing empirical studies and frameworks in conceptual modelling education, and i can position my study among those clusters.*

- **Conceptual Modelling in Education: a Position Paper**  
  → *Again, partly background, but it is also related work: it proposes a particular **view of conceptual modelling education**, which i can later compare with my own findings and emerging theory.*

#### 2.2.3 Existing theories/frameworks (CaMeLOT, Domain Modelling in Bloom, etc.)

- **Domain Modelling in Bloom: Deciphering How We Teach It**  
  → *Provides an **empirical classification** of domain modelling tasks using Bloom; I can treat it as an existing "theory/framework of how tasks target Bloom levels" and compare it to what my participants report.*

- **CaMeLOT: An educational framework for conceptual data modelling**  
  → *Gives a structured **framework of learning outcomes, teaching activities and assessment** for conceptual data modelling. This is one of the main "existing frameworks" my eventual requirements can be compared with, extended, or generalised.*

- **A Framework for Teaching Conceptual Modeling and Metamodeling Based on Bloom's Revised Taxonomy**  
  → *An explicit **Bloom-based teaching framework** with example tasks (Smart City case). Belongs here as a concrete pedagogy framework i can reference and contrast with my obtained data.*

- **Human factors in model-driven engineering: future research goals and initiatives for MDE**  
  → *On the "frameworks" side, this paper provides a **research agenda and conceptual propositions** (e.g., about modeller experience, teaching human-aware MDE). I can treat its propositions as an existing high-level theory that my empirical work can support, nuance, or extend.*

- **Conceptual Modeling Education**  
  → *Also fits here as a high-level framework of the research field (clusters/themes) that i can use to show where my thesis sits in the bigger picture.*

---

### 2.3 Methodology – which papers help which subsections?

#### 2.3.1 Grounded Theory & STGT

- **Grounded Theory in Software Engineering Research: A Critical Review and Guidelines**  
  → *Justification and **checklist** for GT in SE. I will cite it to explain which GT components i adopt (constant comparison, memoing, theoretical sampling, etc.) and how i can/will avoid common pitfalls.*

- **Socio-Technical Grounded Theory for Software Engineering**  
  → *Defines the chosen GT **variant** (STGT) and its socio-technical framing. I will use it to describe the overall approach (basic vs advanced stage, lean vs targeted literature) and to justify why STGT fits studied phenomenon (learning/teaching modelling).*

- **Using grounded theory to study the experience of software development**  
  → *Exemplar GT study. I can reference its procedure and reporting style when explaining my own coding, memoing, theoretical sampling and saturation (e.g., "we followed reporting practices similar to Adolph et al.").*

#### 2.3.2 Bloom-based RQs

- **A Revision of Bloom's Taxonomy: An Overview**  
  → *Source of the revised taxonomy (knowledge × cognitive process). Should use it to justify how i structure my **research questions, interview/survey questions and analysis** around Bloom levels.*

- **A Framework for Teaching Conceptual Modeling and Metamodeling Based on Bloom's Revised Taxonomy**  
  → *Shows how Bloom can be concretely applied to modelling education; useful to justify my decision to map participants' challenges and course tasks to Bloom levels.*

- **Domain Modelling in Bloom: Deciphering How We Teach It**  
  → *Gives me a concrete example of **applying Bloom to classify modelling tasks**, which can inspire my coding scheme for tasks/activities mentioned by participants.*

- **CaMeLOT: An educational framework for conceptual data modelling**  
  → *Provides Bloom-informed learning outcomes; can reference it when designing or analysing how my RQs target different levels of understanding, applying, analysing, etc.*

#### 2.3.3 Survey design

- **Teaching Survey Research in Software Engineering**  
  → *Drives my survey **goal → RQ → metric → question** pipeline (GQM + theory-driven). Also supports how I should think about learning objectives for my survey and instrument evaluation (pilots, expert review).*

- **Challenges in Survey Research**  
  → *Guides my decisions on **sampling, invitations, response rates, representativeness, analysis**, and psychometrics. I should cite it when discussing threats to validity and the limitations of my survey.*

- **Domain Diversity, Motivation, and Inclusion in Software Modelling Education** *(optional)*  
  → *I can cite it as an example of **how to design dual instruments (students + educators)** and as a template for certain Likert/open questions about domains, assignments, and feedback.*

#### 2.3.4 Data collection & analysis

- **Grounded Theory in SE Research** + **Socio-Technical Grounded Theory**  
  → *For the **qualitative side**: explain how i collected interviews/artefacts, did open coding, constant comparison, memoing, and reached saturation, following these guidelines.*

- **Using grounded theory to study the experience of software development**  
  → *Example of presenting **coding steps and emergent categories**; I can mirror its structure in my Findings/Method sections.*

- **Teaching Survey Research in SE** + **Challenges in Survey Research**  
  → *For the **quantitative side** (surveys): describe how I cleaned data, handled Likert scales, performed descriptive/inferential stats, and analysed open answers (possibly using GT/STGT-style coding).*

- **Understanding the challenges and requirements for facilitating iStar learning**  
  → *Acts as a methodological "cousin": another study combining **modelling tasks + interviews + qualitative analysis**. I can refer to it when motivating my choice of combining artefact analysis (models/assignments) with interviews/surveys.*

---

## 3. Brief summaries, key concepts, and main section

*(Ordered roughly by theme, not importance)*

### 3.1 Core foundations

#### 3.1.1 Understanding the challenges and requirements for facilitation iStar learning

- **Role in my thesis:** My baseline empirical study - I will generalise its approach from iStar to broader software modelling/SE frameworks.
- **What it does:**
  - Empirical study (interviews + surveys) with iStar learners.
  - Identifies specific learning challenges (notation complexity, semantic confusion, tool issues, assessment, feedback) and requirements for better support (teaching strategies, tool features, examples, etc).
- **Key concepts:** learning challenges, teaching/assessment practices, requirements for tool and pedagogy.
- **Main sections:**
  - Background and related work (iStar learning, conceptual modelling)
  - Study design (participants, data collection & analysis)
  - Findings: categories of challenges & requirements
  - Implications for teaching & tools
 
#### 3.1.2 Grounded Theory in Software Engineering Research: A Critical Review and Guidelines

- **Role:** Methodological backbone for GT rigour and reporting.
- **What it does:**
  - Reviews ~100 "GT" papers in SE, shows most misuse GT or under-report key aspects.
  - Distils core GT components (constant comparison, memoing, theoretical sampling, saturation, literature role) and proposes a checklist for SE research.
- **Key concepts:** Method slurring, GT variants, core practices, reporting guidelines, epistemological positioning.
- **Main sections:**
  - GT overview (Glaserian, Straussian, Constructivist)
  - Review of GT use in SE
  - Identified problems
  - GT guidelines & checklist
  - Implications for future GT-in-SE work

#### 3.1.3 Socio-Technical Grounded Theory for Software Engineering

- **Role:** My chosen **GT Variant**, especially suitable for socio-technical phenomena like "learning modelling in university context".
- **What it does:**
  - Proposes STGT, a GT-based method tailored to SE's socio-technical nature.
  - Gives a structured process: **basic stage** (core categories) + **advanced stage** (emergent or structured theory development).
  - Clarifies literature strategy (Lean vs Targeted) and reporting.
- **Key concepts:** Socio-technical research dimensions (phenomenon, domain & actors, researcher, data/tools), STGT stages, lean & targeted literature reviews, constant comparison, modifiability of theory.
- **Main sections:**
  - Motivation for STGT
  - Socio-technical research framework
  - STGT process (basic & advanced stages)
  - Guidelines for data collection, coding, memoing, sampling
  - Discussion of validity and generalisability

#### 3.1.4 A Revision of Bloom's Taxonomy: An Overview

- **Role:** Conceptual lens to **structure RQs, learning outcomes, and analysis of tasks/assessments.**
- **What it does:**
  - Introduces revised Bloom's taxonomy with **two dimensions:**
    - Knowledge: factual, conceptual, procedural, metacognitive.
    - Cognitive processes: remember, understand, apply, analyze, evaluate, create.
  - Presents the **Taxonomy Table** and examples of classifying objectives/questions.
- **Key concepts:** Knowledge vs process dimensions, learning objectives alignment, assessment design.
- **Main sections:**
  - Historical Bloom vs revised Bloom
  - The two-dimensional taxonomy
  - Examples of classification
  - Implications for curriculum & assessment


#### 3.1.5 Teaching Survey Research in Software Engineering

- **Role:** Blueprint for my **survey design, LO-style thinking, and reporting.**
- **What it does:**
  - Presents a syllabus for teaching survey research, with **learning objectives**, lecture topics, and assignments.
  - Emphasises aligning research goals -> RQs -> survey questions (GQM + theory-driven)
- **Key concepts:** survey purposes (exploratory/descriptive/explanatory), GQM, instrument design, sampling, instrument evaluation, threats to validity & reliability.
- **Main sections:**
  - Role of surveys in SE
  - Learning objectives & course structure
  - Designing instruments
  - Sampling & administrations
  - Analysis & validity
  - Lessons learned

#### 3.1.6 Challenges in Survey Research

- **Role:** Checklist of **what can go wrong in my survey** and how to mitigate it.
- **What it does:**
  - Discusses challenges in SE survey research: theory building, sampling, invitations, response, rates, statistical & qualitative analysis, psychometrics.
- **Key concepts:** target population, representativeness, open vs closed invitations, analysis pitfalls, reliability & validity, use of psychological scales.
- **Main sections:**
  - Surveys & theory
  - Sampling & invitations
  - Data analysis (qualitative & quantitative)
  - Psychometrics
  - Summary of typical pitfalls & remedies

---

### 3.2 Conceptual/modelling education & Bloom

#### 3.2.1 Conceptual Modeling Education (Maslov et al.)

- **Role:** Big-picture **map of the conceptual modelling education field** and open gaps.
- **What it does:**
  - Bibliometric review of conceptual modelling education literature (topics, venues, methods, co-authorship networks, etc.)
  - Identifies fragmented research and proposes avenues for future research.
- **Key concepts:** research themes (e.g., modelling languages, teaching methods, assessment, tools), bibliometric indicators, gaps in empirical & theory-based work.
- **Main sections:**
  - Method (bibliometric data & process)
  - Results: publication trends, clusters, key authors/venues
  - Identified research themes
  - Avenues for future work (good to tie to my thesis)

#### 3.2.2 Conceptual Modelling in Education: a Position Paper (Buchmann et al.)

- **Role:** Philosophical framing of **what conceptual modelling is** and how students perceive it.
- **What it does:**
  - Argues for conceptual modelling as a **standalone discipline** with a general value propositions, not just a "tool chapter" of SE/DB.
  - Discusses students preconceptions and oversimplifications.
- **Key concepts:** modelling languages as knowledge schemas, design-science framing of modelling education, bridging bachelor-level and research-level understanding.
- **Main sections:**
  - Motivation & problem (preconceptions)
  - Position: modelling as design problem and knowledge schema
  - Implications for teaching & curriculum


#### 3.2.3 A Framework for Teaching Conceptual Modelling and MEtamodelling Based on Bloom's Revised Taxonomy (Bork)

- **Role:** Example of **Bloom-driven teaching framework** for modelling.
- **What it does:**
  - Proposes teaching conceptual modelling and metamodeling by systematically targeting Bloom levels.
  - Uses a **Smart City** case for tasks mapped to different levels.
- **Key concepts:** mapping modelling goals to Bloom cells, designing assignments per level, scaffolding from lower to higher cognitive complexity.
- **Main sections:**
  - Background (Bloom, conceptual modelling)
  - Framework description
  - Example teaching case (Smart City)
  - Evaluation / experiences

#### 3.2.4 Domain Modelling in Bloom: Deciphering How We Teach It (Bagdanova & Snoeck)

- **Role:** Empirical evidence of **how domain modelling is actually taught across materials,** in Bloom terms.
- **What it does:**
  - Analyses domain modelling tasks (from textbooks/courses/exams) and classifies them using revised Bloom.
  - Shows uneven coverage of levels and inconsistent paths.
- **Key concepts:** classification of tasks by level/type, identification of gaps (e.g., underrepresented Analyze/Evaluate/Create)
- **Main sections:**
  - Data collection (tasks)
  - Coding scheme (Bloom)
  - Results and patterns
  - Pedagogical implications


#### 3.2.5 CaMeLOT: An educational framework for conceptual data modelling

- **Role:** Ready-made **framework of learinig outcomes and teaching strategies** for conceptual data modelling.
- **What it does:**
  - Proposes CaMeLOT as a framework defining learning goals, teaching activities, and assessment for conceptual data modelling.
  - Build on Bloom and earlier work to structure concepts & progression.
- **Key concepts:** structured learning outcomes, progression, feedback, teaching patterns for data modelling.
- **Main sections:**
  - Background & problem
  - Design of CaMeLOT
  - Validation / evaluation
  - Lessons for course design



#### 3.2.6 Towards Empirically validated Process Modelling Education Using a BPMN Formalism

- **Role:** Extension of modelling-education research to **process modelling (BPMN)**.
- **What it does:**
  - Argues for empirically validating BPMN-based process modelling education.
  - Proposes steps/agenda for such validation.
- **Key concepts:** BPMN as modelling language, learning outcomes, empirical validation, process-modelling-specific challenges.
- **Main sections:**
  - Context & motivation (BPMN in education)
  - Proposed framework / agenda
  - Preliminary results or plan
  - Research directions


---

### 3.3 Human factors, motivation & SE education

#### 3.3.1 Human factors in model-driven engineering: future research goals and initiatives for MDE

- **Role in thesis:** High-level research agenda that legitimises my human-focused work on modelling learning.
- **What it does:**
  - Summarises discussions from a seminar on human factors in MDE: modelling experience, collaboration, diversity & inclusion, modelling human factor, and teaching human-aware MDE.
  - Section 7 highlights challenges: lack of confidence, feedback difficulties, low motivation, poor emphasis on abstraction and reading models.
- **Key concepts:** modeller experience (MX), human factors, feedback, abstraction, educational strategies.
- **Main sections:**
  - Overview of seminar topics
  - Five thematic areas
  - Propositions & research goals
  - Teaching human-aware MDE
  - Future initiatives

#### 3.3.2 Domain Diversity, Motivation, and Inclusion in Software Modelling Education

- **Role:** Direct evidence for how domain choice, assignment design and feedback shape motivation & inclusion in modelling courses.
- **What it does:**
  - Dual survey (students + educators) on motivating domains, inclusiveness, gamification, collaborations, and feedback.
  - Finds misalignments between what teachers think is motivating and what students actually find motivating; highlights inclusivity issues.
- **Key concepts:** domain diversity, inclusive assignments, motivation, feedback mismatch, gamification & collaboration pitfalls.
- **Main Sections:**
  - Background (DEI & modelling)
  - Study design (instruments for students/educators)
  - Findings
  - Recommendations for assignment & course design


#### 3.3.3 Model Driven Software Engineering in Education: A Multi-Case Study on Perception of Tools and UML

- **Role:** Concrete evidence about **how students perceive modelling tools & UML**.
- **What it does:**
  - Multi-case study across courses, exploring perceptions of MDE tools and UML (complexity, usefulness, barriers).
- **Key concepts:** tool usability, student frustration, perceived value of UML and MDE, institutional constraints.
- **Main sections:**
  - Case descriptions
  - Data collection & analysis
  - Cross-case themes
  - Implications for teaching & tool selection

#### 3.3.4 Dimensions of Experientialism for Software Engineering Education

- **Role:** Broader background on **experiential SE education**, especially capstone/open-source style courses.
- **What it does:**
  - Analyses a programme (UCOSP) to identify dimensions of experientialism (real projects, legacy code, external mentors, etc.)
  - Shows benefits and challenges for students.
- **Key concepts:** experiential learning, capstones, real users, mentorship, authenticity of tasks.
- **Main sections:**
  - Context & programme description
  - Method (qualitative analysis of student feedback)
  - Dimensions identified
  - Implications of curriculum design

#### 3.3.5 A Research Agenda for Identifying and Developing Required Competencies in Software Engineering

- **Role:** Bridge from **modelling challenges** to **SE competencies.**
- **What it does:**
  - Proposes a research agenda to identify and develop SE competencies via interative introduction and evaluation of didactical methods.
- **Key concepts:** competencies vs knowledge, didactics, iterative improvement, research agenda.
- **Main sections:**
  - Motivation (skill gaps, competencies)
  - Proposed approach / agenda
  - Examples of didactical interventions
  - Implications
  

  ---

### 3.4 GT & qualitative examplars

#### 3.4.1 Using grounded theory to study the experience of software development (Adolph et al.)

- **Role:** Example of **GT in practice** (process, coding, reporting style).
- **What it does:**
  - GT study of software developers' experiences; shows how categories emerge, how constant comparison works, and how to build a theory of managing development.
- **Key concepts:** GT coding (open/axial/selective), memoing, theoretical sampling, substantive theory.
- **Main sections:**
  - Method (GT process description)
  - Data & participants
  - Emergent categories & core category
  - Theoretical model
  - Threats to validity


---

## 4. Reading priority list

1. **Conceptual Modeling Education (Maslov et al.)**
2. **Human factors in MDE** - (Section 7 specially)
3. **Domain Modelling in Bloom** 
4. **CaMeLOT**
5. **Conceptual Modeling in Education: a Position Paper**
6. **Domain Diversity, Motivation, and Inclusion in Software Modeling Education**
7. **Model Driven Software Engineering in Education: Perception of Tools and UML**
8. **Towards Empirically Validated Process Modelling Education (BPMN)**
9. **A Framework for Teaching Conceptual Modeling and Metamodeling (Bork)**
10. **A Research Agenda for Identifying and Developing Required Competencies in SE**
11. **Dimensions of Experientialism for SE Education**
12. **Using grounded theory to study the experience of software development**

grischal